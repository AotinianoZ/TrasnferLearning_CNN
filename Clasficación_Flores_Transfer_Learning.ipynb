{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Clasficación_Flores_Transfer_Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "832a9c34f7864142a73ab3bdc2e8b4c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ddc736d8364b43049c6ad0a2d1604764",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2bc85b9b69454398a521b527e8180a0c",
              "IPY_MODEL_a4af3a2b453e4307a859159d48c62eb9"
            ]
          }
        },
        "ddc736d8364b43049c6ad0a2d1604764": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2bc85b9b69454398a521b527e8180a0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ebeb152faf04465f91b1b78ed624a1a2",
            "_dom_classes": [],
            "description": "Dl Completed...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_276798fefba74fbb935401ae126ac1e3"
          }
        },
        "a4af3a2b453e4307a859159d48c62eb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8a893e9dbfbe4118ac8e48cd4345f310",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [04:40&lt;00:00, 56.18s/ file]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fa60d8ddef9e469681fce9bbbcd340bb"
          }
        },
        "ebeb152faf04465f91b1b78ed624a1a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "276798fefba74fbb935401ae126ac1e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8a893e9dbfbe4118ac8e48cd4345f310": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fa60d8ddef9e469681fce9bbbcd340bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AotinianoZ/hello-world/blob/main/Clasficaci%C3%B3n_Flores_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1H9XRT-upJCU"
      },
      "source": [
        "# Clasificación de Flores con Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RVsYZLEpEWs"
      },
      "source": [
        "# Importar\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUCEcRdhnyWn"
      },
      "source": [
        "Algunas librerias para importar que hemos visto anteriormente lo único nuevo es **tensorflow_hub** del cual Colab hace mucho uso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHenfza_ICJL"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEsgwsqbHFn2"
      },
      "source": [
        "import logging\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.ERROR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amfzqn1Oo7Om"
      },
      "source": [
        "# Inicio: Descargar la dataset de flores usando Tensorflow Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z93vvAdGxDMD"
      },
      "source": [
        "En la celda siguiente descargaremso el dataset Flores usando TensorFlow Dataset como anteriormente lo realizamos. Si nosotros miramos la [TensorFlow Datasets documentation](https://www.tensorflow.org/datasets/datasets#tf_flowers) vermos que el nombre del dataset de Flores es `tf_flowers`. Podemos además ver que el dataset esta solo dividido en set Entrenamiento. Deberemos usar `tfds.splits` para separar en un set de `training_set` y `validation_set`. Elegiremos separación `[70, 30]` en el cual 70% corresponde al `training_set` y 30% al `validation_set`. Luego cargaremos dataset `tf_flowers` usando `tfds.load`. Debemos asegurar que la función `tfds.load` usa todos los parámetros necesarios, y además verificar el retorno de la data en la información, así podremos entender el dataset completo.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXiJjX0jfx1o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202,
          "referenced_widgets": [
            "832a9c34f7864142a73ab3bdc2e8b4c5",
            "ddc736d8364b43049c6ad0a2d1604764",
            "2bc85b9b69454398a521b527e8180a0c",
            "a4af3a2b453e4307a859159d48c62eb9",
            "ebeb152faf04465f91b1b78ed624a1a2",
            "276798fefba74fbb935401ae126ac1e3",
            "8a893e9dbfbe4118ac8e48cd4345f310",
            "fa60d8ddef9e469681fce9bbbcd340bb"
          ]
        },
        "outputId": "5455dbc7-66cb-4a6a-8eab-ff42dc1e1225"
      },
      "source": [
        "(training_set, validation_set), dataset_info =  tfds.load(\n",
        "    \"tf_flowers\",\n",
        "    split = [\"train[:70%]\", \"train[70%:]\"],\n",
        "    with_info=True,\n",
        "    as_supervised=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset tf_flowers/3.0.1 (download: 218.21 MiB, generated: 221.83 MiB, total: 440.05 MiB) to /root/tensorflow_datasets/tf_flowers/3.0.1...\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Dataset tf_flowers is hosted on GCS. It will automatically be downloaded to your\n",
            "local data directory. If you'd instead prefer to read directly from our public\n",
            "GCS bucket (recommended if you're running on GCP), you can instead pass\n",
            "`try_gcs=True` to `tfds.load` or set `data_dir=gs://tfds-data/datasets`.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "832a9c34f7864142a73ab3bdc2e8b4c5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Dl Completed...', max=5.0, style=ProgressStyle(descriptio…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1mDataset tf_flowers downloaded and prepared to /root/tensorflow_datasets/tf_flowers/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0p1sOEHf0JF"
      },
      "source": [
        "# Imprimir Información acerca del dataset Flores\n",
        "\n",
        "Ahora que ya hemos descargado el dataset, usaremos la información para imprimir el número de clases del dataset, y además escribir un poco de código para contar cuantas imagenes existen en los sets de entrenamiento y validación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrIUV3V0xDL_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1f1b28d-60fc-4212-ab22-4eef1a13df26"
      },
      "source": [
        "num_classes = dataset_info.features['label'].num_classes\n",
        "\n",
        "num_training_examples = 0\n",
        "num_validation_examples = 0\n",
        "\n",
        "for example in training_set:\n",
        "  num_training_examples += 1\n",
        "\n",
        "for example in validation_set:\n",
        "  num_validation_examples += 1\n",
        "\n",
        "print('Total Number of Classes: {}'.format(num_classes))\n",
        "print('Total Number of Training Images: {}'.format(num_training_examples))\n",
        "print('Total Number of Validation Images: {} \\n'.format(num_validation_examples))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Number of Classes: 5\n",
            "Total Number of Training Images: 2569\n",
            "Total Number of Validation Images: 1101 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlFZ_hwjCLgS"
      },
      "source": [
        "Las images en el dataset Flores **no son del mismo tamaño**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4lDPkn2cpWZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "044c6822-89ed-4f98-f847-f3785144a427"
      },
      "source": [
        "for i, example in enumerate(training_set.take(5)):\n",
        "  print('Image {} shape: {} label: {}'.format(i+1, example[0].shape, example[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image 1 shape: (333, 500, 3) label: 2\n",
            "Image 2 shape: (212, 320, 3) label: 3\n",
            "Image 3 shape: (240, 320, 3) label: 3\n",
            "Image 4 shape: (240, 320, 3) label: 4\n",
            "Image 5 shape: (317, 500, 3) label: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbgpD3E6gM2P"
      },
      "source": [
        "# Reformatear imagenes y crear batches\n",
        "\n",
        "En la celda siguiente crearemos una función que reformatea todas las imagenes a resolución espera de **MobileNet** (*usaremos este objeto para realizar el transfer learning :)*) (224, 224) y lo normalizaremos. La función deberá tomar una `image` y una `label` como argumento y deberá retornar la nueva `image` y la correspondiente `label`. Luego crearemos batches de entrenamiento y validación de tamaño *32*.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "we_ftzQxNf7e"
      },
      "source": [
        "IMAGE_RES = 244\n",
        "\n",
        "def format_image(image, label):\n",
        "  image = tf.image.resize(image, (IMAGE_RES, IMAGE_RES))/255.0\n",
        "  return image, label\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_batches = training_set.shuffle(num_training_examples//4).map(format_image).batch(BATCH_SIZE).prefetch(1) \n",
        "\n",
        "validation_batches = validation_set.map(format_image).batch(BATCH_SIZE).prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzV457OXreQP"
      },
      "source": [
        "# Realizando Simple Transfer Learning con TensorFlow Hub\n",
        "\n",
        "Ahora usaremos *TensorFlow Hub* para hacer el **Transfer Learning**. Recordar, que en el transfer learning usamos parte de un **modelo ya entrenado** Y cambiamos la *capa final*, o muchas capas del modelo, luego reentrenaremos estas capas como nuestro propio dataset :).\n",
        "\n",
        "### Crearemos un extractor de caracteristicas\n",
        "\n",
        "En la celda siguiente crearemos un `feature_extractor` usando *MobileNet v2*. Recordar que el modelo parcial desde TensorFlow Hub (sin la capa de clasificación) es denominado un **vector de caracteristicas**. Ir a [TensorFlow Hub documentation](https://tfhub.dev/s?module-type=image-feature-vector&q=tf2) para ver la lista disponible de vectores de características. Hacemos click en `tf2-preview/mobilenet_v2/feature_vector`. Antes de realizar este trabajo se reviso el URL indicado. Finalmente, se creo `feature_extractor` usando `hub.KerasLayer` con el correcto parámetro de `input_shape`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "me0yF3WO37kD"
      },
      "source": [
        "URL = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
        "feature_extractor = hub.KerasLayer(URL,\n",
        "                                   input_shape=(IMAGE_RES, IMAGE_RES, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtFmF7A5E4tk"
      },
      "source": [
        "### Congelando el Modelo Pre-entrenado\n",
        "\n",
        "En la celda siguiente se 'congelo' las variables en la capa de *feature extractor*, así que el entrenamiento solo modifica la capa final de clasificación.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jg5ar6rcE4H-"
      },
      "source": [
        "feature_extractor.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPVeouTksO9q"
      },
      "source": [
        "### Agregar el cabezal de clasificación\n",
        "\n",
        "En la celda siguiente creamos un modelo `tf.keras.Sequential`, y agregamos un modelo pre-entrenado y la nueva capa de clasificación. La capa de clasificación debe ser el **mismo número de clase** de nuestro dataset Flores. Finalmente imprimimos el sumario del modelo Sequencial.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGcY27fY1q3Q"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  feature_extractor,\n",
        "  tf.keras.layers.Dense(num_classes)\n",
        "])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHbXQqIquFxQ"
      },
      "source": [
        "\n",
        "### Entrenando el Modelo\n",
        "\n",
        "En la celda siguiente entrenamos el modelo como cualquier otro, primero usaremos `compile` y luego `fit`. Debemos asegurarnos que usamos parámetros propios cuando aplicamos ambos métodos. El entrenamiento para 10 epochs.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n0Wb9ylKd8R"
      },
      "source": [
        "model.compile(\n",
        "    optimizer = \"adam\",\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics = [\"accuracy\"]\n",
        ")\n",
        "EPOCHS = 10\n",
        "\n",
        "history = model.fit(train_batches,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=validation_batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76as-K8-vFQJ"
      },
      "source": [
        "Podemos ver que conseguimos *accuracy* validación **~88%** con solo 10 epochs de entrenamiento, esto considero **asombroso**. Este es una *enorme* mejora del modelo creado anteriormente, donde conseguirmos aproximadamente **~78%** de *accuracy* con 100 epochs (se usó data augmentation y variedad de técnicas para mejorar el modelo de predicción). La razón de esta diferencia es que MobilNet v2 fue cuidadosamente diseñado en el tiempo por **expertos**, luego de entrenar dataset masivos (ImageNet).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLxTcprUqJaq"
      },
      "source": [
        "# Ploteo de Gráficos de Entrenamiento y Validación\n",
        "\n",
        "En la celda siguiente, plotea el entramiento y validación con los gráficos de accuracy/loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d28dhbFpr98b"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zmoDisGvNye"
      },
      "source": [
        "Es resaltante que la validación performa es mejor que el entrenamiento performa, correcto desde el inicio al final de la ejecución.\n",
        "\n",
        "Una de las razones es performa es medida al final de los epochs, pero el entrenamiento performa es el promedio de los valores a través de epochs.\n",
        "\n",
        "La mayor razón es pensada porque reusamos una larga parte de *MobileNet* el cuale está entrenado con images de Flores.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb__ZN8uFn-D"
      },
      "source": [
        "# Revisar Predicciones:\n",
        "\n",
        "En la celda siguiente conseguiremos los nombre de las etiquetas desde la información del dataset y lo converterimes en un Numpy array. Imprimiremos el arreglo para asegurarnos los nombre de etiquetas son correctos.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_Zvg2i0fzJu"
      },
      "source": [
        "class_names = np.array(dataset_info.features['label'].names)\n",
        "\n",
        "print(class_names)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Olg6MsNGJTL"
      },
      "source": [
        "### Crear una Batch de Imagen y hacer predicciones\n",
        "\n",
        "En la celda siguiente, usamos la función `next()` para crear una `image_batch` y su correspondiente `label_batch`. Convertiremos ambos `image_batch` y `label_batch` ha arreglos numpy usando el método `.numpy()`. Luego usaremos el método `.predict()` para ejecutar el batch de imagen a través del modelo y hacer predicciones. Después, usaremos la función `np.argmax()` para conseguir los índices de las mejores predicciones para cada imagen. Finalmente, convertiremos los indices de mejor predicción en clases de nombre.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCLVCpEjJ_VP"
      },
      "source": [
        "image_batch, label_batch = next(iter(train_batches))\n",
        "\n",
        "\n",
        "image_batch = image_batch.numpy()\n",
        "label_batch = label_batch.numpy()\n",
        "\n",
        "predicted_batch = model.predict(image_batch)\n",
        "predicted_batch = tf.squeeze(predicted_batch).numpy()\n",
        "\n",
        "predicted_ids = np.argmax(predicted_batch, axis=-1)\n",
        "predicted_class_names = class_names[predicted_ids]\n",
        "\n",
        "print(predicted_class_names)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkGbZxl9GZs-"
      },
      "source": [
        "### Imprimiendo True Labels y Predicted Indices\n",
        "\n",
        "En la celda siguiente, imprimiremos las etiquetas verdadero y el indice de etiquetas predecido."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL9IhOmGI5dJ"
      },
      "source": [
        "print(\"Labels:           \", label_batch)\n",
        "print(\"Predicted labels: \", predicted_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJDyzEfYuFcW"
      },
      "source": [
        "# Plotear Predicciones del Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wC_AYRJU9NQe"
      },
      "source": [
        "plt.figure(figsize=(10,9))\n",
        "for n in range(30):\n",
        "  plt.subplot(6,5,n+1)\n",
        "  plt.subplots_adjust(hspace = 0.3)\n",
        "  plt.imshow(image_batch[n])\n",
        "  color = \"blue\" if predicted_ids[n] == label_batch[n] else \"red\"\n",
        "  plt.title(predicted_class_names[n].title(), color=color)\n",
        "  plt.axis('off')\n",
        "_ = plt.suptitle(\"Model predictions (blue: correct, red: incorrect)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QBKxS5CuKhc"
      },
      "source": [
        "# Mejorar el Transfer Learning con el Inception Model\n",
        "\n",
        "Por úttimo se me ocurrió mejorar esto con el Inception Model ir a [TensorFlow Hub documentation](https://tfhub.dev/s?module-type=image-feature-vector&q=tf2) y click en `tf2-preview/inception_v3/feature_vector`. Este vector corresponde al modelo **Inception v3 model**. En la celda siguiente, usaremos transfer learning para crear una CNN que usa el Inception v3 como el modelo preentrenado para clasificar imagenes desde el dataset de Flores. La entrada de inception es *299x299* pixeles. Compararemos las precisiones entre :\n",
        "\n",
        "**Inception v3 ** Vs. **MobileNet v2**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlYCFvmt5mEZ"
      },
      "source": [
        "IMAGE_RES = 299\n",
        "\n",
        "(training_set, validation_set), dataset_info = tfds.load(\n",
        "    'tf_flowers', \n",
        "    with_info=True, \n",
        "    as_supervised=True, \n",
        "    split=['train[:70%]', 'train[70%:]'],\n",
        ")\n",
        "train_batches = training_set.shuffle(num_training_examples//4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "validation_batches = validation_set.map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "\n",
        "URL = \"https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4\"\n",
        "feature_extractor = hub.KerasLayer(URL,\n",
        "  input_shape=(IMAGE_RES, IMAGE_RES, 3),\n",
        "  trainable=False)\n",
        "\n",
        "model_inception = tf.keras.Sequential([\n",
        "  feature_extractor,\n",
        "  tf.keras.layers.Dense(num_classes)\n",
        "])\n",
        "\n",
        "model_inception.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2bk-Zcq5qzW"
      },
      "source": [
        "model_inception.compile(\n",
        "  optimizer='adam', \n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "EPOCHS = 6\n",
        "\n",
        "history = model_inception.fit(train_batches,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=validation_batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ7k497vyMiw"
      },
      "source": [
        "# Conclusiones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwYuF8ityO5G"
      },
      "source": [
        "* Usar los **transfer learning** mejoran mucho la velocidad de procesamiento y la precisión con una cantidad mucho menor de batches, además nos permiten ahorrar mucho tiempo al momento de un análisis preliminar.\n",
        "\n",
        "* La mejora del uso de transfer learning mejoró la **accuracy** de ~78% hasta ~87%.\n",
        "\n",
        "* Al comparar modelos de **transfer learning** (Inception v3 y MobilNet v2) nos dio mejores resultados en ....\n",
        "\n",
        "* La idea de probar y comparar nuevos modelos y cambios en la estructura de la neurona puede proporcionar mejoras significativas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5Z5sn2Hy27y"
      },
      "source": [
        "# Recomendaciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkqhZEJay4YD"
      },
      "source": [
        "* No todos los tipos de data se adecuan a los modelos de transfer learning.\n",
        "\n",
        "* Se requiere trabajos de muchos expertos y validados en el tiempo para usar el transfer learning (alguien que haya trabajado previamente), por lo cual se hace escaso para otros tipos de trabajos como el de Ingeniería Geológica (en mi caso."
      ]
    }
  ]
}